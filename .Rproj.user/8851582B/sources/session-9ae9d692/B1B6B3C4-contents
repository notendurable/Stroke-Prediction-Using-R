# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on building and deploying a stroke prediction model in R. It contains analysis such as data exploration, summary statistics and building the prediction models. The final report was completed on `r date()`. 

**Data Description:**

According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.

This data set is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relevant information about the patient.


# Task One: Import data and data preprocessing

## Load data and install packages

```{r setup, message=FALSE, warning=FALSE}
# Load libraries
library(tidyverse)
library(tidymodels)
library(caret)
library(pROC)
library(randomForest)
library(e1071)
library(xgboost)
library(rpart)
library(rpart.plot)
library(workflows)
library(recipes)
library(ggplot2)
library(mice)
library(reshape2)
library(kernlab)
library(yardstick)
library(knitr)

# Load the stroke dataset
stroke_data <- read.csv("C:/Users/emman/OneDrive/Desktop/Data Science Projects/Stroke Prediction Project/healthcare-dataset-stroke-data.csv") %>%
  select(-id) %>%
  mutate(
    stroke = factor(stroke, levels = c(0, 1), labels = c("No", "Yes")),
    gender = factor(gender),
    hypertension = factor(hypertension, levels = c(0, 1), labels = c("No", "Yes")),
    heart_disease = factor(heart_disease, levels = c(0, 1), labels = c("No", "Yes")),
    ever_married = factor(ever_married),
    work_type = factor(work_type),
    Residence_type = factor(Residence_type),
    smoking_status = factor(smoking_status),
    bmi = as.numeric(ifelse(bmi == "N/A", NA, bmi))
  ) %>%
  mutate(bmi = ifelse(is.na(bmi), median(bmi, na.rm = TRUE), bmi))

# Summarize the data
summary(stroke_data)
```


```{r}
# Handle Missing bmi Values
stroke_data$bmi <- ifelse(is.na(stroke_data$bmi), median(stroke_data$bmi, na.rm = TRUE), stroke_data$bmi)
```


```{r}
# Check correlations to understand the relationships between numeric variables
cor_matrix <- cor(stroke_data %>%
  select(age, avg_glucose_level, bmi), use = "complete.obs")

# Print the correlation matrix
print(cor_matrix)

# # Correlation heatmap
# melted_cor <- melt(cor_matrix)
# ggplot(data = melted_cor, aes(Var1, Var2, fill = value)) +
#   geom_tile() +
#   scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
#   labs(title = "Correlation Heatmap") +
#   theme_minimal()

# # Check Correlations to understand the relationships between numeric variables and detect multicollinearity
# cor_matrix <- cor(stroke_data %>% 
#                             select(age, avg_glucose_level, bmi), use = "complete.obs")
# print(cor_matrix)
```




## Describe and explore the data

```{r, message=FALSE, warning=FALSE}
# Structure of the dataset
str(stroke_data)

# Summary statistics of numeric variables
summary(stroke_data)

# Check for missing values
colSums(is.na(stroke_data))

# Class distribution
stroke_data %>%
  count(stroke) %>%
  ggplot(aes(x = stroke, fill = stroke)) +
  geom_bar() +
  labs(title = "Class Distribution", y = "Count") +
  theme_minimal()

# Correlation heatmap
cor_matrix <- cor(stroke_data %>%
  select(age, avg_glucose_level, bmi), use = "complete.obs")
melted_cor <- melt(cor_matrix)
ggplot(data = melted_cor, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Heatmap") +
  theme_minimal()

# Numeric Variables by Stroke
ggplot(stroke_data, aes(x = bmi, fill = stroke)) +
  geom_histogram(bins = 30, position = "dodge") +
  theme_minimal() +
  labs(title = "Distribution of BMI by Stroke")

# Categorical Variables by stroke
ggplot(stroke_data, aes(x = gender, fill = stroke)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Gender Distribution by Stroke")


# Class Distribution
# Stroke class distribution
stroke_data %>%
  count(stroke) %>%
  mutate(percent = n / sum(n) * 100)

# Bar plot of stroke distribution
ggplot(stroke_data, aes(x = stroke, fill = stroke)) +
  geom_bar() +
  labs(title = "Stroke Class Distribution", y = "Count") +
  theme_minimal()

## Numerical variables

# Summary Statistics
stroke_data %>%
  select(age, avg_glucose_level, bmi) %>%
  summary()

stroke_data %>%
  select(age, avg_glucose_level, bmi) %>%
  summary()

# Distribution of Age
ggplot(stroke_data, aes(x = age, fill = stroke)) +
  geom_histogram(bins = 30, position = "dodge") +
  labs(title = "Age Distribution by Stroke", x = "Age") +
  theme_minimal()

# Distribution of Average Glucose Level
ggplot(stroke_data, aes(x = avg_glucose_level, fill = stroke)) +
  geom_density(alpha = 0.5) +
  labs(title = "Average Glucose Level Distribution by Stroke", x = "Avg Glucose Level") +
  theme_minimal()

# Distribution of BMI
ggplot(stroke_data, aes(x = bmi, fill = stroke)) +
  geom_histogram(bins = 30, position = "dodge") +
  theme_minimal() +
  labs(title = "Distribution of BMI by Stroke")


# Exploratory Data Visualization

## Categorical Variables

stroke_data %>%
  count(gender, stroke) %>%
  ggplot(aes(x = gender, fill = stroke)) +
  geom_bar(position = "fill") +
  labs(title = "Gender Distribution by Stroke", y = "Proportion") +
  theme_minimal()

stroke_data %>%
  count(work_type, stroke) %>%
  ggplot(aes(x = work_type, fill = stroke)) +
  geom_bar(position = "fill") +
  labs(title = "Work Type Distribution by Stroke", y = "Proportion") +
  theme_minimal()

# Variables relationship
# Correlation matrix
cor_matrix <- stroke_data %>%
  select(age, avg_glucose_level, bmi) %>%
  cor(use = "complete.obs")

print(cor_matrix)

# Correlation heatmap
melted_cor <- melt(cor_matrix)
ggplot(data = melted_cor, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Matrix") +
  theme_minimal()

# Outlier Detection
# Boxplots for numeric variables
stroke_data %>%
  select(age, avg_glucose_level, bmi) %>%
  gather(key = "Variable", value = "Value") %>%
  ggplot(aes(x = Variable, y = Value, fill = Variable)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Boxplots of Numeric Variables")


# Bivariate Relationships
# Relationship between Age and Stroke
ggplot(stroke_data, aes(x = age, y = avg_glucose_level, color = stroke)) +
  geom_point(alpha = 0.7) +
  labs(title = "Age vs. Avg Glucose Level by Stroke", x = "Age", y = "Avg Glucose Level") +
  theme_minimal()
```


# Task Two: Build prediction models. 

```{r}
# Set seed for reproducibility
set.seed(123)

# Split the data into 75/25 for training and testing sets
split_data <- initial_split(stroke_data, prop = 0.75)
train_data <- training(split_data)
test_data <- testing(split_data)
```


```{r}
# Logistic Regression
log_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Random Forest
rf_spec <- rand_forest(mtry = 3, trees = 500, min_n = 10) %>%
  set_engine("ranger") %>%
  set_mode("classification")

# Support Vector Machine
svm_spec <- svm_poly(degree = 3, cost = 1) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

# Decision Tree
tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# XGBoost
xgb_spec <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("classification")


# Create a preprocessing recipe
model_recipe <- recipe(stroke ~ age + avg_glucose_level + bmi + gender + hypertension + 
                         heart_disease + ever_married + work_type + Residence_type + smoking_status, 
                       data = train_data) %>%
  step_dummy(all_nominal_predictors()) %>%  # Convert categorical variables to numeric
  step_normalize(all_numeric_predictors()) # Normalize numeric variables
```

# Task Three: Evaluate and select prediction models

```{r}
# Train models
models <- list(
  Logistic_Regression = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(log_spec) %>%
    fit(data = train_data),
  Random_Forest = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(rf_spec) %>%
    fit(data = train_data),
  Support_Vector_Machine = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(svm_spec) %>%
    fit(data = train_data),
  Decision_Tree = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(tree_spec) %>%
    fit(data = train_data),
  XGBoost = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(xgb_spec) %>%
    fit(data = train_data)
)

# Updated Evaluation Function
evaluation_metrics <- function(model, test_data) {
  # Generate predictions
  predictions <- predict(model, test_data, type = "prob") %>%
    bind_cols(predict(model, test_data)) %>%
    bind_cols(test_data)
  
  # Ensure predictions include the necessary columns
  if (!all(c(".pred_class", ".pred_Yes") %in% colnames(predictions))) {
    stop("Predictions do not include required columns.")
  }
  
  # Confusion Matrix
  conf_matrix <- tryCatch(
    conf_mat(predictions, truth = stroke, estimate = .pred_class),
    error = function(e) {
      warning("Error in creating confusion matrix: ", conditionMessage(e))
      NULL
    }
  )
  
  # Metrics: Accuracy, ROC AUC, Precision, Recall, F1-score
  metrics <- tryCatch(
    {
      metrics(predictions, truth = stroke, estimate = .pred_class) %>%
        bind_rows(
          roc_auc(predictions, truth = stroke, .pred_Yes),
          yardstick::precision(predictions, truth = stroke, estimate = .pred_class),
          yardstick::recall(predictions, truth = stroke, estimate = .pred_class),
          yardstick::f_meas(predictions, truth = stroke, estimate = .pred_class)
        )
    },
    error = function(e) {
      warning("Error in calculating metrics: ", conditionMessage(e))
      NULL
    }
  )
  
  list(
    metrics = metrics,
    confusion_matrix = conf_matrix
  )
}

# Evaluate all models
results <- lapply(models, function(model) {
  tryCatch(
    evaluation_metrics(model, test_data = test_data),
    error = function(e) {
      warning("Error in model evaluation: ", conditionMessage(e))
      NULL
    }
  )
})
names(results) <- names(models)

# Check for NULL entries in results
if (any(sapply(results, is.null))) {
  warning("Some models failed during evaluation.")
}

# Extract evaluation metrics
evaluation_results <- bind_rows(
  lapply(results, function(x) if (!is.null(x)) x$metrics else NULL),
  .id = "Model"
)

# Extract confusion matrices
confusion_matrices <- lapply(results, function(x) if (!is.null(x)) x$confusion_matrix else NULL)

# Check if confusion matrices were created successfully
if (any(sapply(confusion_matrices, is.null))) {
  warning("Some confusion matrices could not be created.")
}
```


```{r}
# View metrics for all models
#print(evaluation_results)
kable(evaluation_results,
      col.names = c("Model", "Metric", "Estimator", "Estimate"))

# View confusion matrix for each model
print(confusion_matrices$Logistic_Regression)
print(confusion_matrices$Random_Forest)
print(confusion_matrices$Support_Vector_Machine)
print(confusion_matrices$Decision_Tree)
print(confusion_matrices$XGBoost)
```



# Task Four: Deploy the prediction model

**Note:** The Stroke Prediction will be deploy using R Shiny. The code below will prepare and save the Logistic Regression Model and Random Forest Model to be deploy using R Shiny.  

```{r}
# Save models to files
saveRDS(models$Logistic_Regression, "logistic_regression_model.rds")
saveRDS(models$Random_Forest, "random_forest_model.rds")
saveRDS(models$Support_Vector_Machine, "support_vector_machine_model.rds")  # Corrected model name
saveRDS(models$Decision_Tree, "decision_tree_model.rds")
saveRDS(models$XGBoost, "xgboost_model.rds")

# Save evaluation metrics to a CSV file
write.csv(evaluation_results, "evaluation_metrics.csv", row.names = FALSE)

# Save confusion matrices to a file
saveRDS(confusion_matrices, "confusion_matrices.rds")

# Save predictions to a file
predictions <- lapply(models, function(model) {
  tryCatch(
    {
      predict(model, test_data, type = "prob") %>%
        bind_cols(predict(model, test_data)) %>%
        bind_cols(test_data)
    },
    error = function(e) {
      warning("Error in generating predictions for a model: ", conditionMessage(e))
      NULL
    }
  )
})
names(predictions) <- names(models)

# Remove NULL predictions (if any)
predictions <- predictions[!sapply(predictions, is.null)]

saveRDS(predictions, "model_predictions.rds")
```


# Task Five: Findings and Conclusions

**Stroke Risk Prediction Project: Findings and Conclusions**

**Project Overview**

According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths. This project utilized machine learning techniques to predict the risk of stroke based on various demographic, clinical, and lifestyle factors. By leveraging multiple models, this study aimed to identify the most effective prediction model and evaluate its performance metrics. The dataset used included variables such as age, gender, average glucose level, BMI, hypertension, heart disease, marital status, work type, residence type, and smoking status.The outcome variable was stroke. Since stroke ("0", "1", or "Yes", "No") is a binary classification variable, we deployed five binary classification models to answer our research question. 

**Machine Learning Models Used**

**Logistic Regression:** A baseline statistical model commonly used for binary classification problems. It was used to provide a reference point for model performance. Logistic regression has interpretable coefficients that indicate the relationship between predictors and the probability of stroke. The logistic regression achieved an accuracy of 94.75% but had a low ROC AUC score of 0.15, indicating poor discrimination for positive cases.

**Random Forest:** A robust ensemble model that combines multiple decision trees to reduce overfitting and improve generalization. The random forest model achieved high accuracy (94.75%) and perfect recall (1.00), but a low ROC AUC score (0.17), highlighting challenges in ranking probabilities effectively. 

**Support Vector Machine (SVM):** Suitable for complex relationships in data, with its ability to map features into high-dimensional space for better separation. The SVM model achieved accuracy of 91.86% with an improved ROC AUC score (0.34). This model balanced precision and recall, making it a better candidate for stroke prediction compared to Random Forest.

**Decision Tree:**  Provides an intuitive representation of decision-making, making it easy to interpret for medical practitioners. The decision model achieved similar accuracy to Logistic Regression (94.75%), but its ROC AUC score was also limited (0.50). The model showed high precision (94.75%) and recall (100%), indicating its reliability in binary classification tasks.

**XGBoost:** A highly efficient and scalable gradient boosting model that is popular for tabular data. It handles missing data, reduces bias and variance, and provides strong predictive performance. The XGBoost model achieved the highest accuracy (94.52%) and ROC AUC (0.16). It showed excellent recall (99.75%) and precision (94.75%).

**Performance Metrics**

Key metrics were used to evaluate model performance, providing insight into classification accuracy and balance between false positives and negatives of stroke risk prediction. Accuracy: The proportion of correct predictions out of all predictions. ROC AUC: Measures the ability of the model to distinguish between classes. Precision: Indicates the proportion of positive identifications that were correct. Recall (Sensitivity): Proportion of actual positives correctly identified. F1-Score: The harmonic mean of precision and recall, balancing the two.

**Findings**

Logistic Regression and Decision Tree achieved similar accuracy but performed poorly in ROC AUC, indicating challenges in ranking probabilities for positive cases. SVM demonstrated a balance between precision and recall, but its ROC AUC score (0.34) suggested room for improvement. Random Forest and XGBoost exhibited high recall, crucial for identifying true positives in stroke prediction, but suffered from low ROC AUC scores.

Models like Random Forest and XGBoost had perfect recall, predicting all true positives effectively, but also showed false positives, reducing precision. Logistic Regression struggled with positive cases, as evidenced by lower recall and ROC AUC scores.

Random Forest and XGBoost provided insights into feature importance, with age, average glucose level, and BMI emerging as the most significant predictors of stroke risk. Lifestyle factors, such as smoking status and work type, were less impactful but still contributed to model predictions.

The dataset had a significant class imbalance, with a majority of negative cases. This affected metrics like ROC AUC and precision. Most models struggled to differentiate positive cases effectively, as reflected in low ROC AUC values.

XGBoost emerged as the best model for stroke prediction, balancing high accuracy, precision, and recall while handling complex feature interactions effectively. SVM provided a reliable alternative, especially when precision and recall needed to be balanced.

Clinical factors like age, BMI, and average glucose level significantly influenced stroke predictions, highlighting the need for targeted interventions in at-risk populations. Demographic and lifestyle factors had secondary importance, suggesting opportunities for public health campaigns.

**Practical Implications:**

The findings can guide clinicians in early stroke risk assessment, especially for patients with elevated glucose levels or BMI. Models with high recall, like Random Forest and XGBoost, can be deployed in medical settings to minimize missed diagnoses.

**Future Work:**

Using techniques like SMOTE (Synthetic Minority Oversampling Technique) or undersampling to balance classes could improve performance. Combining predictions from multiple models could enhance overall performance. Validating models on external datasets or in clinical settings would ensure robustness and reliability.

**Recommendations**

Deploy XGBoost or Random Forest in Clinical Settings: These models demonstrated high sensitivity, ensuring that high-risk patients are not missed.

Focus on Data Quality: Collecting more balanced datasets with equal representation of stroke-positive cases can improve model generalizability.

Integrate Risk Models into Decision Support Systems: Embedding models into electronic health records can aid clinicians in real-time risk assessment.

Educate Stakeholders: Public health officials and clinicians should be trained to interpret model outputs and leverage insights for preventive care.